{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 2:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 3 Max Value: 219\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 3 Name: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxv43XI8p802nQmEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78a56becc0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 2\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, *image_shape], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,(None, n_classes), name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    shape = [*conv_ksize, int(x_tensor.shape[3]), conv_num_outputs]\n",
    "    weight = tf.Variable(tf.random_normal(shape, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_strides = [1, *conv_strides, 1]\n",
    "    cs = tf.nn.conv2d(x_tensor, weight, strides=conv_strides, padding='SAME')\n",
    "    \n",
    "    csb = tf.nn.bias_add(cs, bias)\n",
    "    csc = tf.nn.relu(csb)\n",
    "    \n",
    "    pool_ksize = [1, *pool_ksize, 1]\n",
    "    pool_strides = [1, *pool_strides, 1]\n",
    "    convmax_tens = tf.nn.max_pool(csc, pool_ksize, pool_strides, padding='SAME')\n",
    "    return convmax_tens\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    batch_size, *img_size = x_tensor.get_shape().as_list()\n",
    "    img_size = img_size[0] * img_size[1] * img_size[2]\n",
    "    f_tensor = tf.reshape(x_tensor, [-1, img_size])\n",
    "    return f_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    shape = (int(x_tensor.get_shape().as_list()[1]), num_outputs)\n",
    "    weight = tf.Variable(tf.random_normal(shape, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    x = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    f_tensor = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    shape = [int(x_tensor.get_shape().as_list()[1]), num_outputs]\n",
    "    weight = tf.Variable(tf.random_normal(shape, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    f_tensor = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    \n",
    "    return f_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    x_tensor = x\n",
    "    conv_num_outputs = 384\n",
    "    conv_ksize = (3,3)\n",
    "    conv_strides = (1,1)\n",
    "    pool_ksize = (2,2)\n",
    "    pool_strides = (2,2)\n",
    "    num_outputs = 10\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "\n",
    "    x = conv2d_maxpool(x, 32, (3, 3), (1, 1), (2, 2), (2, 2))\n",
    "    x = conv2d_maxpool(x, 32, (3, 3), (2, 2), (2, 2), (2, 2))\n",
    "    x = conv2d_maxpool(x, 64, (3, 3), (1, 1), (2, 2), (2, 2))\n",
    "\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    flat = flatten(x)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    fconn1 = fully_conn(flat, 512)\n",
    "    fconn1b = tf.nn.dropout(fconn1, keep_prob)\n",
    "    \n",
    "    fconn2 = fully_conn(fconn1b, 128)\n",
    "    fconn2b = tf.nn.dropout(fconn2, keep_prob)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    f_tensor = output(fconn2b, num_outputs)\n",
    "\n",
    "    \n",
    "    # TODO: return output\n",
    "    return f_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict = {x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    \n",
    "    acc = session.run(accuracy, feed_dict = {x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    \n",
    "    print(\"Loss: {}\".format(loss), \"Validation Accuracy: {}\".format(acc))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 60\n",
    "batch_size = 256\n",
    "keep_probability = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.0376510620117188 Validation Accuracy: 0.31359997391700745\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.6730971336364746 Validation Accuracy: 0.37119996547698975\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.4040851593017578 Validation Accuracy: 0.41739997267723083\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.239956259727478 Validation Accuracy: 0.4177999496459961\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.0396981239318848 Validation Accuracy: 0.4399999678134918\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 0.8681390285491943 Validation Accuracy: 0.4607999324798584\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 0.7354512810707092 Validation Accuracy: 0.47519999742507935\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 0.6471853852272034 Validation Accuracy: 0.49039995670318604\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 0.5762906670570374 Validation Accuracy: 0.4925999641418457\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 0.5058881044387817 Validation Accuracy: 0.507599949836731\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.4664130210876465 Validation Accuracy: 0.5153999328613281\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.4245626926422119 Validation Accuracy: 0.5221999287605286\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.3677300810813904 Validation Accuracy: 0.5221999883651733\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.3081650137901306 Validation Accuracy: 0.5273999571800232\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.2858782708644867 Validation Accuracy: 0.5153999328613281\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.27103984355926514 Validation Accuracy: 0.5089999437332153\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.2232576310634613 Validation Accuracy: 0.5383999347686768\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.21452948451042175 Validation Accuracy: 0.5227999687194824\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.19895963370800018 Validation Accuracy: 0.517799973487854\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.16924738883972168 Validation Accuracy: 0.52239990234375\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.18732154369354248 Validation Accuracy: 0.5113999843597412\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.17668935656547546 Validation Accuracy: 0.5187999606132507\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.14710862934589386 Validation Accuracy: 0.5187999606132507\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.11666014045476913 Validation Accuracy: 0.5223999619483948\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.10355298221111298 Validation Accuracy: 0.5219999551773071\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.11615221202373505 Validation Accuracy: 0.525399923324585\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.14503785967826843 Validation Accuracy: 0.5107999444007874\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.1213207021355629 Validation Accuracy: 0.5113999247550964\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.18583612143993378 Validation Accuracy: 0.4915999472141266\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.09164246171712875 Validation Accuracy: 0.506399929523468\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.09900573641061783 Validation Accuracy: 0.50819993019104\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.08936414122581482 Validation Accuracy: 0.5077999830245972\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.0972248762845993 Validation Accuracy: 0.5073999762535095\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.07282863557338715 Validation Accuracy: 0.5185999870300293\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.12662675976753235 Validation Accuracy: 0.4941999316215515\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.07036815583705902 Validation Accuracy: 0.5161999464035034\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.07952409982681274 Validation Accuracy: 0.5081999897956848\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.07640568912029266 Validation Accuracy: 0.5073999166488647\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.08174993097782135 Validation Accuracy: 0.501599907875061\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.07381380349397659 Validation Accuracy: 0.5005999803543091\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.08406930416822433 Validation Accuracy: 0.4941999912261963\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.050508320331573486 Validation Accuracy: 0.5051999688148499\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.07388836145401001 Validation Accuracy: 0.4975999593734741\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.05725394934415817 Validation Accuracy: 0.5047999620437622\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.07953885942697525 Validation Accuracy: 0.48399996757507324\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.04623853415250778 Validation Accuracy: 0.5137999057769775\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.07250652462244034 Validation Accuracy: 0.49619996547698975\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.03488760069012642 Validation Accuracy: 0.4983999729156494\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.024236446246504784 Validation Accuracy: 0.5245999693870544\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.04250207543373108 Validation Accuracy: 0.5107999444007874\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.018043357878923416 Validation Accuracy: 0.5215999484062195\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.03336472064256668 Validation Accuracy: 0.5121999382972717\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.03347119316458702 Validation Accuracy: 0.5021999478340149\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.06745092570781708 Validation Accuracy: 0.4959999620914459\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.01915094070136547 Validation Accuracy: 0.5095999240875244\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.029376165941357613 Validation Accuracy: 0.4943999648094177\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.029340390115976334 Validation Accuracy: 0.49519994854927063\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.03884439915418625 Validation Accuracy: 0.48499998450279236\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.02707105316221714 Validation Accuracy: 0.4875999689102173\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.017232943326234818 Validation Accuracy: 0.4989999830722809\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.0668911933898926 Validation Accuracy: 0.2943999767303467\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 1.6089494228363037 Validation Accuracy: 0.4063999652862549\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 1.3468756675720215 Validation Accuracy: 0.4229999780654907\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 1.3710925579071045 Validation Accuracy: 0.4650000035762787\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 1.3995543718338013 Validation Accuracy: 0.47739994525909424\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 1.43455171585083 Validation Accuracy: 0.5051999688148499\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 1.2893919944763184 Validation Accuracy: 0.49119997024536133\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 0.9708694219589233 Validation Accuracy: 0.4825999438762665\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 1.0481934547424316 Validation Accuracy: 0.5166000127792358\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 1.2324658632278442 Validation Accuracy: 0.515999972820282\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 1.1657977104187012 Validation Accuracy: 0.5399999022483826\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.0999606847763062 Validation Accuracy: 0.5509999394416809\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 0.7548959255218506 Validation Accuracy: 0.5367999076843262\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 0.8508798480033875 Validation Accuracy: 0.5427999496459961\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.053004264831543 Validation Accuracy: 0.5465999245643616\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 0.9811122417449951 Validation Accuracy: 0.5661998987197876\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 0.9071382284164429 Validation Accuracy: 0.5643999576568604\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 0.6208734512329102 Validation Accuracy: 0.5803999304771423\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 0.7078813910484314 Validation Accuracy: 0.5761998891830444\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 0.8592798113822937 Validation Accuracy: 0.5845999121665955\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 0.8651461601257324 Validation Accuracy: 0.5811998844146729\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 0.789849579334259 Validation Accuracy: 0.5737999677658081\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 0.5318477153778076 Validation Accuracy: 0.6035999059677124\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 0.6251367330551147 Validation Accuracy: 0.5933999419212341\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 0.6864261627197266 Validation Accuracy: 0.5989999175071716\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 0.7576639652252197 Validation Accuracy: 0.5995998978614807\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 0.6587976217269897 Validation Accuracy: 0.5995999574661255\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 0.4327978789806366 Validation Accuracy: 0.6141998767852783\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 0.5682023763656616 Validation Accuracy: 0.6047998666763306\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 0.5681947469711304 Validation Accuracy: 0.6059998869895935\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 0.6936641931533813 Validation Accuracy: 0.6057999134063721\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 0.5566672086715698 Validation Accuracy: 0.6079999208450317\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 0.38055771589279175 Validation Accuracy: 0.6201998591423035\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 0.4851331114768982 Validation Accuracy: 0.6161999106407166\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 0.5195336937904358 Validation Accuracy: 0.6107999086380005\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 0.5956042408943176 Validation Accuracy: 0.6115999221801758\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 0.44506949186325073 Validation Accuracy: 0.6155999302864075\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 0.33421096205711365 Validation Accuracy: 0.6273998618125916\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 0.45516330003738403 Validation Accuracy: 0.6217999458312988\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 0.4555152654647827 Validation Accuracy: 0.6107999086380005\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 0.5407392978668213 Validation Accuracy: 0.6153998970985413\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 0.40344515442848206 Validation Accuracy: 0.6201999187469482\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 0.3094494044780731 Validation Accuracy: 0.6305999159812927\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 0.46849772334098816 Validation Accuracy: 0.6075999140739441\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 0.41011977195739746 Validation Accuracy: 0.6253998875617981\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 0.47477006912231445 Validation Accuracy: 0.6171998977661133\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 0.36683499813079834 Validation Accuracy: 0.624799907207489\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 0.27802830934524536 Validation Accuracy: 0.637799859046936\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 0.4201817214488983 Validation Accuracy: 0.612799882888794\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 0.3799186050891876 Validation Accuracy: 0.6169998645782471\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 0.3936775326728821 Validation Accuracy: 0.6333999037742615\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 0.3231457769870758 Validation Accuracy: 0.6329998970031738\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 0.2314535677433014 Validation Accuracy: 0.6405999064445496\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 0.3645700216293335 Validation Accuracy: 0.6235998868942261\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 0.3379506468772888 Validation Accuracy: 0.6173999309539795\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 0.3837108016014099 Validation Accuracy: 0.6213998794555664\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 0.2770697772502899 Validation Accuracy: 0.6345999240875244\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 0.21354635059833527 Validation Accuracy: 0.6429998874664307\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 0.3379218280315399 Validation Accuracy: 0.6215998530387878\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 0.31038928031921387 Validation Accuracy: 0.6307999491691589\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 0.3651966154575348 Validation Accuracy: 0.6277998685836792\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 0.25692203640937805 Validation Accuracy: 0.6371999382972717\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 0.2043449729681015 Validation Accuracy: 0.6367999315261841\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 0.3137495517730713 Validation Accuracy: 0.6237998604774475\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 0.28544965386390686 Validation Accuracy: 0.6317998766899109\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 0.31489062309265137 Validation Accuracy: 0.6281999349594116\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 0.22412630915641785 Validation Accuracy: 0.6349999308586121\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 0.2041596621274948 Validation Accuracy: 0.6291999220848083\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 0.2766617238521576 Validation Accuracy: 0.6315999031066895\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 0.24107608199119568 Validation Accuracy: 0.6405999064445496\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 0.2838485836982727 Validation Accuracy: 0.6285999417304993\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 0.21372203528881073 Validation Accuracy: 0.6361998915672302\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 0.19731375575065613 Validation Accuracy: 0.6281998753547668\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 0.26460105180740356 Validation Accuracy: 0.6283999085426331\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 0.19126158952713013 Validation Accuracy: 0.6451999545097351\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 0.2542530298233032 Validation Accuracy: 0.6299998760223389\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 0.20507828891277313 Validation Accuracy: 0.637799859046936\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 0.18518441915512085 Validation Accuracy: 0.6233999133110046\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 0.23542964458465576 Validation Accuracy: 0.6307998895645142\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 0.17503038048744202 Validation Accuracy: 0.6427998542785645\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 0.22621478140354156 Validation Accuracy: 0.6311999559402466\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 0.18487045168876648 Validation Accuracy: 0.6367998719215393\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 0.1663217544555664 Validation Accuracy: 0.619399905204773\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 0.2207506150007248 Validation Accuracy: 0.625999927520752\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 0.18301549553871155 Validation Accuracy: 0.6373999118804932\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 0.2030712366104126 Validation Accuracy: 0.6345999240875244\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 0.18168003857135773 Validation Accuracy: 0.6351999044418335\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 0.15803149342536926 Validation Accuracy: 0.6185998916625977\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 0.22946950793266296 Validation Accuracy: 0.6205998659133911\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 0.16388225555419922 Validation Accuracy: 0.6339998841285706\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 0.21187248826026917 Validation Accuracy: 0.6393998861312866\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 0.1787703037261963 Validation Accuracy: 0.637199878692627\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 0.16296181082725525 Validation Accuracy: 0.6205999255180359\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 0.2140653133392334 Validation Accuracy: 0.6251998543739319\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 0.16027657687664032 Validation Accuracy: 0.6407999396324158\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 0.19966809451580048 Validation Accuracy: 0.6389999389648438\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 0.18668067455291748 Validation Accuracy: 0.6335998773574829\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 0.15431463718414307 Validation Accuracy: 0.6189998388290405\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 0.20542176067829132 Validation Accuracy: 0.6317998766899109\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 0.14489246904850006 Validation Accuracy: 0.6311998963356018\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 0.20182354748249054 Validation Accuracy: 0.6405999660491943\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 0.1746368110179901 Validation Accuracy: 0.6393998861312866\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 0.16281306743621826 Validation Accuracy: 0.619999885559082\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 0.1916237324476242 Validation Accuracy: 0.6357998847961426\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 0.14181998372077942 Validation Accuracy: 0.6293998956680298\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 0.20317068696022034 Validation Accuracy: 0.6451998949050903\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 0.17249158024787903 Validation Accuracy: 0.637199878692627\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 0.15811273455619812 Validation Accuracy: 0.6223998665809631\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 0.17431694269180298 Validation Accuracy: 0.6429998874664307\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 0.15238544344902039 Validation Accuracy: 0.6261999607086182\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 0.21194884181022644 Validation Accuracy: 0.6357999444007874\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 0.20025292038917542 Validation Accuracy: 0.6311999559402466\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 0.14842438697814941 Validation Accuracy: 0.627799928188324\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 0.18575915694236755 Validation Accuracy: 0.6413998603820801\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 0.1537126898765564 Validation Accuracy: 0.6191998720169067\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 0.20396046340465546 Validation Accuracy: 0.6445999145507812\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 0.1789456605911255 Validation Accuracy: 0.6329998970031738\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 0.13826434314250946 Validation Accuracy: 0.624799907207489\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 0.176051065325737 Validation Accuracy: 0.6461998820304871\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 0.14402395486831665 Validation Accuracy: 0.6215999126434326\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 0.1866268664598465 Validation Accuracy: 0.6473998427391052\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 0.16242744028568268 Validation Accuracy: 0.6345999240875244\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 0.1348869651556015 Validation Accuracy: 0.626599907875061\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 0.2025221735239029 Validation Accuracy: 0.6393998861312866\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 0.14042900502681732 Validation Accuracy: 0.6219998598098755\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 0.17598804831504822 Validation Accuracy: 0.6519998908042908\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 0.1551886647939682 Validation Accuracy: 0.6333999037742615\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 0.13285678625106812 Validation Accuracy: 0.6309999227523804\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 0.20094723999500275 Validation Accuracy: 0.644399881362915\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 0.13213297724723816 Validation Accuracy: 0.6289998888969421\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 0.17593511939048767 Validation Accuracy: 0.6505998969078064\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 0.13744273781776428 Validation Accuracy: 0.6375998854637146\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 0.10746873170137405 Validation Accuracy: 0.6433999538421631\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 0.2042272835969925 Validation Accuracy: 0.6459999084472656\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 0.1271425038576126 Validation Accuracy: 0.6331998705863953\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 0.1810465306043625 Validation Accuracy: 0.6467999219894409\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 0.15951408445835114 Validation Accuracy: 0.6267999410629272\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 0.10974007099866867 Validation Accuracy: 0.6457998752593994\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 0.1888328194618225 Validation Accuracy: 0.6385998725891113\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 0.12805870175361633 Validation Accuracy: 0.6317998766899109\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 0.1826774626970291 Validation Accuracy: 0.6467998623847961\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 0.14099986851215363 Validation Accuracy: 0.6325998902320862\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 0.11455556750297546 Validation Accuracy: 0.6447998285293579\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 0.18397265672683716 Validation Accuracy: 0.6411998867988586\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 0.13367068767547607 Validation Accuracy: 0.6267999410629272\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 0.1946796178817749 Validation Accuracy: 0.6393999457359314\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 0.12908688187599182 Validation Accuracy: 0.6391998529434204\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 0.10889874398708344 Validation Accuracy: 0.6369999051094055\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 0.17305561900138855 Validation Accuracy: 0.640799880027771\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 0.11725630611181259 Validation Accuracy: 0.6351999044418335\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 0.1814543604850769 Validation Accuracy: 0.6441999077796936\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 0.11686979979276657 Validation Accuracy: 0.6467998623847961\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 0.11104948818683624 Validation Accuracy: 0.6361998915672302\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 0.1649188995361328 Validation Accuracy: 0.6433998942375183\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 0.10981413722038269 Validation Accuracy: 0.6401998996734619\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 0.15053406357765198 Validation Accuracy: 0.6441999077796936\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 0.12091114372015 Validation Accuracy: 0.6461998820304871\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 0.11617505550384521 Validation Accuracy: 0.6253998279571533\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 0.1541810780763626 Validation Accuracy: 0.650999903678894\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 0.11064916104078293 Validation Accuracy: 0.6405999064445496\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 0.15126335620880127 Validation Accuracy: 0.6453999280929565\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 0.12580551207065582 Validation Accuracy: 0.6459999084472656\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 0.108831025660038 Validation Accuracy: 0.6241999268531799\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 0.14290207624435425 Validation Accuracy: 0.64739990234375\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 0.10799660533666611 Validation Accuracy: 0.6365998983383179\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 0.13678568601608276 Validation Accuracy: 0.6431999206542969\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 0.1306290179491043 Validation Accuracy: 0.64739990234375\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 0.1000688374042511 Validation Accuracy: 0.6289998888969421\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 0.13352903723716736 Validation Accuracy: 0.6503999829292297\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 0.1195509284734726 Validation Accuracy: 0.6253999471664429\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 0.1287221759557724 Validation Accuracy: 0.6457999348640442\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 0.12914544343948364 Validation Accuracy: 0.645599901676178\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 0.10431621968746185 Validation Accuracy: 0.6299998760223389\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 0.13136151432991028 Validation Accuracy: 0.6489998698234558\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 0.09464247524738312 Validation Accuracy: 0.6339998841285706\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 0.13714149594306946 Validation Accuracy: 0.6485998630523682\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 0.1285414844751358 Validation Accuracy: 0.6485998630523682\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 0.09852638095617294 Validation Accuracy: 0.6359999179840088\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 0.12700442969799042 Validation Accuracy: 0.6515999436378479\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 0.08035349100828171 Validation Accuracy: 0.6353999376296997\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 0.12204472720623016 Validation Accuracy: 0.6507998704910278\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 0.11896662414073944 Validation Accuracy: 0.6501998901367188\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 0.09997628629207611 Validation Accuracy: 0.6393999457359314\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 0.10831436514854431 Validation Accuracy: 0.6499999165534973\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 0.07849615812301636 Validation Accuracy: 0.6345998644828796\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 0.11980573832988739 Validation Accuracy: 0.6495999097824097\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 0.11999249458312988 Validation Accuracy: 0.6505998969078064\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 0.07547077536582947 Validation Accuracy: 0.6459998488426208\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 0.11082520335912704 Validation Accuracy: 0.6503998637199402\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 0.07990080118179321 Validation Accuracy: 0.6323999166488647\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 0.13509055972099304 Validation Accuracy: 0.643799901008606\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 0.109372079372406 Validation Accuracy: 0.6483998894691467\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 0.07822702080011368 Validation Accuracy: 0.6375999450683594\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 0.13030344247817993 Validation Accuracy: 0.6493999361991882\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 0.09228628873825073 Validation Accuracy: 0.6347998976707458\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 0.1341046243906021 Validation Accuracy: 0.6393998861312866\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 0.11674614250659943 Validation Accuracy: 0.6369999051094055\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 0.09096048772335052 Validation Accuracy: 0.6097999215126038\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 0.13333995640277863 Validation Accuracy: 0.6417999267578125\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 0.09359999001026154 Validation Accuracy: 0.6353999376296997\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 0.15251508355140686 Validation Accuracy: 0.6277999877929688\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 0.12188111245632172 Validation Accuracy: 0.6445999145507812\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 0.07899267971515656 Validation Accuracy: 0.6039999127388\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 0.14277151226997375 Validation Accuracy: 0.6279998421669006\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 0.10652820020914078 Validation Accuracy: 0.6327999234199524\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 0.15781839191913605 Validation Accuracy: 0.6301998496055603\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 0.11554703116416931 Validation Accuracy: 0.637199878692627\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 0.07817703485488892 Validation Accuracy: 0.6113999485969543\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 0.13751932978630066 Validation Accuracy: 0.6275999546051025\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 0.08772523701190948 Validation Accuracy: 0.6237999200820923\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 0.12075239419937134 Validation Accuracy: 0.6373999118804932\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 0.11095790565013885 Validation Accuracy: 0.6381999254226685\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 0.08396375924348831 Validation Accuracy: 0.6015998125076294\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 0.1456778347492218 Validation Accuracy: 0.6293998956680298\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 0.09067961573600769 Validation Accuracy: 0.6263998746871948\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 0.12221089005470276 Validation Accuracy: 0.6283999085426331\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 0.10286260396242142 Validation Accuracy: 0.6305999159812927\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 0.07756435871124268 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 0.1439710259437561 Validation Accuracy: 0.6351998448371887\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 0.07865363359451294 Validation Accuracy: 0.6377999186515808\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 0.11587673425674438 Validation Accuracy: 0.6321998834609985\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 0.09418296813964844 Validation Accuracy: 0.6255999207496643\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 0.07620682567358017 Validation Accuracy: 0.6095998883247375\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 0.13573817908763885 Validation Accuracy: 0.6347999572753906\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 0.06952150911092758 Validation Accuracy: 0.6475999355316162\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 0.11823349446058273 Validation Accuracy: 0.6311999559402466\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 0.08669900894165039 Validation Accuracy: 0.6331998705863953\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 0.06938271969556808 Validation Accuracy: 0.6089998483657837\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 0.1348595768213272 Validation Accuracy: 0.6445998549461365\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 0.07336960732936859 Validation Accuracy: 0.6557998657226562\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 0.11085131764411926 Validation Accuracy: 0.6333999037742615\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 0.08367586880922318 Validation Accuracy: 0.6347998380661011\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 0.06779246777296066 Validation Accuracy: 0.6121999025344849\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 0.13630084693431854 Validation Accuracy: 0.638999879360199\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 0.06913234293460846 Validation Accuracy: 0.6529998779296875\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 0.1083214208483696 Validation Accuracy: 0.6341999173164368\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 0.08280827105045319 Validation Accuracy: 0.6385999321937561\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 0.07679584622383118 Validation Accuracy: 0.5989999175071716\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 0.1243952214717865 Validation Accuracy: 0.6393998861312866\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 0.07334523648023605 Validation Accuracy: 0.6461998224258423\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 0.10977663844823837 Validation Accuracy: 0.6401998996734619\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 0.09111718088388443 Validation Accuracy: 0.6421998739242554\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 0.07290836423635483 Validation Accuracy: 0.596799910068512\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 0.137533500790596 Validation Accuracy: 0.6307998299598694\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 0.06632909923791885 Validation Accuracy: 0.6363998651504517\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 0.09962897002696991 Validation Accuracy: 0.6419999599456787\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 0.08796339482069016 Validation Accuracy: 0.6361998319625854\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 0.07123047858476639 Validation Accuracy: 0.5989998579025269\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 0.13040345907211304 Validation Accuracy: 0.6243999004364014\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 0.07102760672569275 Validation Accuracy: 0.6285998821258545\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss: 0.11038701981306076 Validation Accuracy: 0.6361998915672302\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss: 0.08137515932321548 Validation Accuracy: 0.6381998658180237\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss: 0.08711450546979904 Validation Accuracy: 0.6021998524665833\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss: 0.11939412355422974 Validation Accuracy: 0.6299998760223389\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss: 0.08205662667751312 Validation Accuracy: 0.6303998827934265\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss: 0.10717712342739105 Validation Accuracy: 0.6289999485015869\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss: 0.08905994892120361 Validation Accuracy: 0.630599856376648\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss: 0.07070466876029968 Validation Accuracy: 0.6091998815536499\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss: 0.1248997375369072 Validation Accuracy: 0.6367998719215393\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss: 0.0756758600473404 Validation Accuracy: 0.637799859046936\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss: 0.11454986780881882 Validation Accuracy: 0.6391998529434204\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss: 0.0786912739276886 Validation Accuracy: 0.6301999092102051\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss: 0.0754004642367363 Validation Accuracy: 0.6081998944282532\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss: 0.11717523634433746 Validation Accuracy: 0.6365998983383179\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss: 0.07349252700805664 Validation Accuracy: 0.6421998739242554\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss: 0.10808549076318741 Validation Accuracy: 0.6355998516082764\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss: 0.07656922936439514 Validation Accuracy: 0.6293998956680298\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss: 0.07145053148269653 Validation Accuracy: 0.6075999140739441\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss: 0.10388451814651489 Validation Accuracy: 0.6335998773574829\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss: 0.07085984945297241 Validation Accuracy: 0.6425999402999878\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss: 0.11296580731868744 Validation Accuracy: 0.6357998847961426\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss: 0.08610282093286514 Validation Accuracy: 0.6209998726844788\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss: 0.07783965021371841 Validation Accuracy: 0.6067999601364136\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss: 0.08747629821300507 Validation Accuracy: 0.6389998197555542\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss: 0.06703980267047882 Validation Accuracy: 0.6339998841285706\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss: 0.12471037358045578 Validation Accuracy: 0.6295998692512512\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss: 0.09731121361255646 Validation Accuracy: 0.626599907875061\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss: 0.07460924237966537 Validation Accuracy: 0.6065998673439026\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss: 0.09167146682739258 Validation Accuracy: 0.634199857711792\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss: 0.06673289835453033 Validation Accuracy: 0.6333999037742615\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss: 0.13135004043579102 Validation Accuracy: 0.6283998489379883\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss: 0.10259600728750229 Validation Accuracy: 0.627799928188324\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss: 0.07181952893733978 Validation Accuracy: 0.619999885559082\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss: 0.11282183229923248 Validation Accuracy: 0.619999885559082\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss: 0.06150598078966141 Validation Accuracy: 0.6379998326301575\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss: 0.12924014031887054 Validation Accuracy: 0.6345999240875244\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss: 0.10529595613479614 Validation Accuracy: 0.6207998991012573\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss: 0.05679047107696533 Validation Accuracy: 0.6301999092102051\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss: 0.10521082580089569 Validation Accuracy: 0.6205998659133911\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss: 0.054555583745241165 Validation Accuracy: 0.6335998773574829\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss: 0.10714162886142731 Validation Accuracy: 0.6405998468399048\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss: 0.09608328342437744 Validation Accuracy: 0.629599928855896\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss: 0.04040129855275154 Validation Accuracy: 0.6395999193191528\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss: 0.0816153734922409 Validation Accuracy: 0.6207998991012573\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss: 0.05029051750898361 Validation Accuracy: 0.6255999207496643\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss: 0.1004473865032196 Validation Accuracy: 0.638999879360199\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss: 0.08278825879096985 Validation Accuracy: 0.6335999965667725\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss: 0.04679038003087044 Validation Accuracy: 0.640799880027771\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss: 0.08348322659730911 Validation Accuracy: 0.6195998787879944\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss: 0.056090131402015686 Validation Accuracy: 0.6281999349594116\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.63857421875\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIhIpOBYRERERif4fYwRHJO0tK4wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78943c0438>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
